{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brats_data_loader import get_list_of_patients, get_train_transform, BRATSDataLoader\n",
    "from train_test_function import ModelTrainer\n",
    "from jonas_net import AlbuNet3D34\n",
    "\n",
    "from batchgenerators.utilities.data_splitting import get_split_deterministic\n",
    "from batchgenerators.dataloading import MultiThreadedAugmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = get_list_of_patients('brats_data_preprocessed/Brats17TrainingData')\n",
    "batch_size = 2 # 24\n",
    "patch_size = [24, 128, 128]\n",
    "in_channels = ['t1c', 't2', 'flair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_splits=5 means 1/5th is validation data!\n",
    "patients_train, patients_val = get_split_deterministic(patients, fold=0, num_splits=5, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = BRATSDataLoader(\n",
    "    patients_train,\n",
    "    batch_size=batch_size,\n",
    "    patch_size=patch_size,\n",
    "    in_channels=in_channels\n",
    ")\n",
    "\n",
    "val_dl = BRATSDataLoader(\n",
    "    patients_val,\n",
    "    batch_size=batch_size,\n",
    "    patch_size=patch_size,\n",
    "    in_channels=in_channels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_transforms = get_train_transform(patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally we can create multithreaded transforms that we can actually use for training\n",
    "# we don't pin memory here because this is pytorch specific.\n",
    "tr_gen = MultiThreadedAugmenter(train_dl, tr_transforms, num_processes=4,\n",
    "                                num_cached_per_queue=3,\n",
    "                                seeds=None, pin_memory=False)\n",
    "# we need less processes for vlaidation because we dont apply transformations\n",
    "val_gen = MultiThreadedAugmenter(val_dl, None,\n",
    "                                 num_processes=max(1, 4 // 2),\n",
    "                                 num_cached_per_queue=1,\n",
    "                                 seeds=None,\n",
    "                                 pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_gen.restart()\n",
    "val_gen.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(outputs, targets):\n",
    "\n",
    "    # try without sigmoid\n",
    "    # outputs = F.sigmoid(outputs)\n",
    "    outputs = (outputs>0).float()\n",
    "    smooth = 1e-15\n",
    "\n",
    "    targets = (targets == 1).float()\n",
    "    union_fg = (outputs+targets).sum() + smooth\n",
    "    intersection_fg = (outputs*targets).sum() + smooth\n",
    "\n",
    "    dice = 2 * intersection_fg / union_fg\n",
    "\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differentiable version of the dice metric\n",
    "class SimpleDiceLoss():\n",
    "    def __call__(self, outputs, targets):\n",
    "\n",
    "        # try without sigmoid\n",
    "        # outputs = F.sigmoid(outputs)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        # outputs = (outputs>0).float()\n",
    "        smooth = 1e-15\n",
    "        \n",
    "        targets = (targets == 1).float()\n",
    "        union_fg = (outputs+targets).sum() + smooth\n",
    "        intersection_fg = (outputs*targets).sum() + smooth\n",
    "        \n",
    "        dice = 2 * intersection_fg / union_fg\n",
    "\n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_3d = AlbuNet3D34(pretrained=True, is_deconv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we went from 1e-2 to 1e-1\n",
    "# wang uses 1e-3, isensee uses 1e-4*5 and decays it 0.985 every epoch, original albunet goes from 1e-3 to 1e-4\n",
    "# wang uses 1e-7 weight decay, isensee 1e-5\n",
    "optimizer = optim.Adam(net_3d.parameters(), lr=1e-2, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = ModelTrainer('jonas_net_3d', net_3d, tr_gen, val_gen, SimpleDiceLoss(), dice,\n",
    "                             lr=0.001, epochs=10,\n",
    "                             num_batches_per_epoch=10, num_validation_batches_per_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] Avg. Loss: 0.95, Avg. Metric: 0.05%\n",
      "\n",
      "# Epoch 1 #\n",
      "\n",
      "[Train] Avg. Loss: 0.97, Avg. Metric: 0.06%\n",
      "[Val] Avg. Loss: 0.96, Avg. Metric: 0.22%\n",
      "\n",
      "# Epoch 2 #\n",
      "\n",
      "[Train] Avg. Loss: 0.94, Avg. Metric: 0.20%\n",
      "[Val] Avg. Loss: 1.00, Avg. Metric: 0.00%\n",
      "\n",
      "# Epoch 3 #\n",
      "\n",
      "[Train] Avg. Loss: 0.98, Avg. Metric: 0.08%\n",
      "[Val] Avg. Loss: 0.89, Avg. Metric: 0.30%\n",
      "\n",
      "# Epoch 4 #\n",
      "\n",
      "[Train] Avg. Loss: 0.97, Avg. Metric: 0.11%\n",
      "[Val] Avg. Loss: 0.96, Avg. Metric: 0.08%\n",
      "\n",
      "# Epoch 5 #\n",
      "\n",
      "[Train] Avg. Loss: 0.99, Avg. Metric: 0.06%\n",
      "[Val] Avg. Loss: 0.94, Avg. Metric: 0.15%\n",
      "\n",
      "# Epoch 6 #\n",
      "\n",
      "[Train] Avg. Loss: 0.95, Avg. Metric: 0.18%\n",
      "[Val] Avg. Loss: 0.99, Avg. Metric: 0.03%\n",
      "\n",
      "# Epoch 7 #\n",
      "\n",
      "[Train] Avg. Loss: 0.97, Avg. Metric: 0.10%\n",
      "[Val] Avg. Loss: 0.99, Avg. Metric: 0.11%\n",
      "\n",
      "# Epoch 8 #\n",
      "\n",
      "[Train] Avg. Loss: 0.90, Avg. Metric: 0.29%\n",
      "[Val] Avg. Loss: 0.97, Avg. Metric: 0.15%\n",
      "\n",
      "# Epoch 9 #\n",
      "\n",
      "[Train] Avg. Loss: 0.97, Avg. Metric: 0.06%\n",
      "[Val] Avg. Loss: 0.97, Avg. Metric: 0.08%\n",
      "\n",
      "# Epoch 10 #\n",
      "\n",
      "[Train] Avg. Loss: 0.92, Avg. Metric: 0.21%\n",
      "[Val] Avg. Loss: 0.97, Avg. Metric: 0.07%\n",
      "\n",
      "Time elapsed: 2214.51 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2214.5091140270233"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
