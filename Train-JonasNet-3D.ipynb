{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brats_data_loader import get_list_of_patients, get_train_transform, iterate_through_patients, BRATSDataLoader\n",
    "from train_test_function import ModelTrainer\n",
    "from jonas_net import AlbuNet3D34\n",
    "\n",
    "from batchgenerators.utilities.data_splitting import get_split_deterministic\n",
    "from batchgenerators.dataloading import MultiThreadedAugmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = get_list_of_patients('brats_data_preprocessed/Brats17TrainingData')\n",
    "batch_size = 24 # 24\n",
    "patch_size = [24, 128, 128]\n",
    "in_channels = ['t1c', 't2', 'flair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_splits=5 means 1/5th is validation data!\n",
    "patients_train, patients_val = get_split_deterministic(patients, fold=0, num_splits=5, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_test = get_list_of_patients('brats_data_preprocessed/Brats18ValidationData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = BRATSDataLoader(\n",
    "    patients_train,\n",
    "    batch_size=batch_size,\n",
    "    patch_size=patch_size,\n",
    "    in_channels=in_channels\n",
    ")\n",
    "\n",
    "val_dl = BRATSDataLoader(\n",
    "    patients_val,\n",
    "    batch_size=batch_size,\n",
    "    patch_size=patch_size,\n",
    "    in_channels=in_channels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_transforms = get_train_transform(patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally we can create multithreaded transforms that we can actually use for training\n",
    "# we don't pin memory here because this is pytorch specific.\n",
    "tr_gen = MultiThreadedAugmenter(train_dl, tr_transforms, num_processes=4, # tr_transforms\n",
    "                                num_cached_per_queue=3,\n",
    "                                seeds=None, pin_memory=False)\n",
    "# we need less processes for vlaidation because we dont apply transformations\n",
    "val_gen = MultiThreadedAugmenter(val_dl, None,\n",
    "                                 num_processes=max(1, 4 // 2),\n",
    "                                 num_cached_per_queue=1,\n",
    "                                 seeds=None,\n",
    "                                 pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_gen.restart()\n",
    "val_gen.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [1, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A == 1) | (A == 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(outputs, targets):\n",
    "\n",
    "    # try without sigmoid\n",
    "    # outputs = F.sigmoid(outputs)\n",
    "    outputs = (outputs>0).float()\n",
    "    smooth = 1e-15\n",
    "\n",
    "    targets = ((targets == 1) | (targets == 3)).float()\n",
    "    union_fg = (outputs+targets).sum() + smooth\n",
    "    intersection_fg = (outputs*targets).sum() + smooth\n",
    "\n",
    "    dice = 2 * intersection_fg / union_fg\n",
    "\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differentiable version of the dice metric\n",
    "class SimpleDiceLoss():\n",
    "    def __call__(self, outputs, targets):\n",
    "\n",
    "        # try without sigmoid\n",
    "        # outputs = F.sigmoid(outputs)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        # outputs = (outputs>0).float()\n",
    "        smooth = 1e-15\n",
    "        \n",
    "        targets = ((targets == 1) | (targets == 3)).float()\n",
    "        union_fg = (outputs+targets).sum() + smooth\n",
    "        intersection_fg = (outputs*targets).sum() + smooth\n",
    "        \n",
    "        dice = 2 * intersection_fg / union_fg\n",
    "\n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_3d = AlbuNet3D34(pretrained=True, is_deconv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we went from 1e-2 to 1e-1\n",
    "# wang uses 1e-3, isensee uses 1e-4*5 and decays it 0.985 every epoch, original albunet goes from 1e-3 to 1e-4\n",
    "# wang uses 1e-7 weight decay, isensee 1e-5\n",
    "# optimizer = optim.Adam(net_3d.parameters(), lr=1e-2, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = ModelTrainer('jonas_net_3d_brats17_pretr', net_3d, tr_gen, val_gen, SimpleDiceLoss(), dice,\n",
    "                             lr=1e-4, epochs=50,\n",
    "                             num_batches_per_epoch=100, num_validation_batches_per_epoch=100, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] Avg. Loss: 0.96, Avg. Metric: 0.04\n",
      "\n",
      "# Epoch 1 #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with proposed augmentations\n",
    "# pretrained 2017\n",
    "# lr=0.0001, epochs=50, num_batches_per_epoch=100, num_validation_batches_per_epoch=100\n",
    "# ~4.5 hrs\n",
    "# batch_size = 24, patch_size = [24, 128, 128]\n",
    "model_trainer.run()\n",
    "model_trainer.save_model('models/pr_augm_lr_0001_epochs_100_bs_24_brats17.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] Avg. Loss: 0.96, Avg. Metric: 0.04\n",
      "\n",
      "# Epoch 1 #\n",
      "\n",
      "[Train] Avg. Loss: 0.95, Avg. Metric: 0.05\n",
      "[Val] Avg. Loss: 0.92, Avg. Metric: 0.07\n",
      "\n",
      "# Epoch 2 #\n",
      "\n",
      "[Train] Avg. Loss: 0.93, Avg. Metric: 0.08\n",
      "[Val] Avg. Loss: 0.92, Avg. Metric: 0.13\n",
      "\n",
      "# Epoch 3 #\n",
      "\n",
      "[Train] Avg. Loss: 0.93, Avg. Metric: 0.18\n",
      "[Val] Avg. Loss: 0.91, Avg. Metric: 0.27\n",
      "\n",
      "# Epoch 4 #\n",
      "\n",
      "[Train] Avg. Loss: 0.93, Avg. Metric: 0.26\n",
      "[Val] Avg. Loss: 0.91, Avg. Metric: 0.46\n",
      "\n",
      "# Epoch 5 #\n",
      "\n",
      "[Train] Avg. Loss: 0.93, Avg. Metric: 0.52\n",
      "[Val] Avg. Loss: 0.90, Avg. Metric: 0.64\n",
      "\n",
      "# Epoch 6 #\n",
      "\n",
      "[Train] Avg. Loss: 0.93, Avg. Metric: 0.61\n",
      "[Val] Avg. Loss: 0.90, Avg. Metric: 0.53\n",
      "\n",
      "# Epoch 7 #\n",
      "\n",
      "[Train] Avg. Loss: 0.92, Avg. Metric: 0.66\n",
      "[Val] Avg. Loss: 0.90, Avg. Metric: 0.69\n",
      "\n",
      "# Epoch 8 #\n",
      "\n",
      "[Train] Avg. Loss: 0.91, Avg. Metric: 0.65\n",
      "[Val] Avg. Loss: 0.90, Avg. Metric: 0.72\n",
      "\n",
      "# Epoch 9 #\n",
      "\n",
      "[Train] Avg. Loss: 0.91, Avg. Metric: 0.67\n",
      "[Val] Avg. Loss: 0.89, Avg. Metric: 0.72\n",
      "\n",
      "# Epoch 10 #\n",
      "\n",
      "[Train] Avg. Loss: 0.90, Avg. Metric: 0.69\n",
      "[Val] Avg. Loss: 0.88, Avg. Metric: 0.71\n",
      "\n",
      "# Epoch 11 #\n",
      "\n",
      "[Train] Avg. Loss: 0.91, Avg. Metric: 0.68\n",
      "[Val] Avg. Loss: 0.88, Avg. Metric: 0.71\n",
      "\n",
      "# Epoch 12 #\n",
      "\n",
      "[Train] Avg. Loss: 0.89, Avg. Metric: 0.71\n",
      "[Val] Avg. Loss: 0.87, Avg. Metric: 0.72\n",
      "\n",
      "# Epoch 13 #\n",
      "\n",
      "[Train] Avg. Loss: 0.89, Avg. Metric: 0.70\n",
      "[Val] Avg. Loss: 0.87, Avg. Metric: 0.70\n",
      "\n",
      "# Epoch 14 #\n",
      "\n",
      "[Train] Avg. Loss: 0.88, Avg. Metric: 0.73\n",
      "[Val] Avg. Loss: 0.86, Avg. Metric: 0.74\n",
      "\n",
      "# Epoch 15 #\n",
      "\n",
      "[Train] Avg. Loss: 0.87, Avg. Metric: 0.70\n",
      "[Val] Avg. Loss: 0.84, Avg. Metric: 0.73\n",
      "\n",
      "# Epoch 16 #\n",
      "\n",
      "[Train] Avg. Loss: 0.85, Avg. Metric: 0.74\n",
      "[Val] Avg. Loss: 0.83, Avg. Metric: 0.76\n",
      "\n",
      "# Epoch 17 #\n",
      "\n",
      "[Train] Avg. Loss: 0.85, Avg. Metric: 0.75\n",
      "[Val] Avg. Loss: 0.82, Avg. Metric: 0.75\n",
      "\n",
      "# Epoch 18 #\n",
      "\n",
      "[Train] Avg. Loss: 0.84, Avg. Metric: 0.74\n",
      "[Val] Avg. Loss: 0.82, Avg. Metric: 0.72\n",
      "\n",
      "# Epoch 19 #\n",
      "\n",
      "[Train] Avg. Loss: 0.82, Avg. Metric: 0.78\n",
      "[Val] Avg. Loss: 0.79, Avg. Metric: 0.78\n",
      "\n",
      "# Epoch 20 #\n",
      "\n",
      "[Train] Avg. Loss: 0.79, Avg. Metric: 0.79\n",
      "[Val] Avg. Loss: 0.77, Avg. Metric: 0.83\n",
      "\n",
      "# Epoch 21 #\n",
      "\n",
      "[Train] Avg. Loss: 0.78, Avg. Metric: 0.79\n",
      "[Val] Avg. Loss: 0.73, Avg. Metric: 0.76\n",
      "\n",
      "# Epoch 22 #\n",
      "\n",
      "[Train] Avg. Loss: 0.75, Avg. Metric: 0.81\n",
      "[Val] Avg. Loss: 0.70, Avg. Metric: 0.83\n",
      "\n",
      "# Epoch 23 #\n",
      "\n",
      "[Train] Avg. Loss: 0.71, Avg. Metric: 0.83\n",
      "[Val] Avg. Loss: 0.69, Avg. Metric: 0.81\n",
      "\n",
      "# Epoch 24 #\n",
      "\n",
      "[Train] Avg. Loss: 0.70, Avg. Metric: 0.82\n",
      "[Val] Avg. Loss: 0.65, Avg. Metric: 0.84\n",
      "\n",
      "# Epoch 25 #\n",
      "\n",
      "[Train] Avg. Loss: 0.66, Avg. Metric: 0.85\n",
      "[Val] Avg. Loss: 0.61, Avg. Metric: 0.82\n",
      "\n",
      "# Epoch 26 #\n",
      "\n",
      "[Train] Avg. Loss: 0.61, Avg. Metric: 0.85\n",
      "[Val] Avg. Loss: 0.57, Avg. Metric: 0.83\n",
      "\n",
      "# Epoch 27 #\n",
      "\n",
      "[Train] Avg. Loss: 0.57, Avg. Metric: 0.86\n",
      "[Val] Avg. Loss: 0.55, Avg. Metric: 0.82\n",
      "\n",
      "# Epoch 28 #\n",
      "\n",
      "[Train] Avg. Loss: 0.54, Avg. Metric: 0.88\n",
      "[Val] Avg. Loss: 0.52, Avg. Metric: 0.82\n",
      "\n",
      "# Epoch 29 #\n",
      "\n",
      "[Train] Avg. Loss: 0.52, Avg. Metric: 0.87\n",
      "[Val] Avg. Loss: 0.48, Avg. Metric: 0.84\n",
      "\n",
      "# Epoch 30 #\n",
      "\n",
      "[Train] Avg. Loss: 0.47, Avg. Metric: 0.88\n",
      "[Val] Avg. Loss: 0.45, Avg. Metric: 0.84\n",
      "\n",
      "# Epoch 31 #\n",
      "\n",
      "[Train] Avg. Loss: 0.44, Avg. Metric: 0.88\n",
      "[Val] Avg. Loss: 0.41, Avg. Metric: 0.86\n",
      "\n",
      "# Epoch 32 #\n",
      "\n",
      "[Train] Avg. Loss: 0.42, Avg. Metric: 0.88\n",
      "[Val] Avg. Loss: 0.39, Avg. Metric: 0.86\n",
      "\n",
      "# Epoch 33 #\n",
      "\n",
      "[Train] Avg. Loss: 0.39, Avg. Metric: 0.89\n",
      "[Val] Avg. Loss: 0.38, Avg. Metric: 0.83\n",
      "\n",
      "# Epoch 34 #\n",
      "\n",
      "[Train] Avg. Loss: 0.35, Avg. Metric: 0.89\n",
      "[Val] Avg. Loss: 0.33, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 35 #\n",
      "\n",
      "[Train] Avg. Loss: 0.31, Avg. Metric: 0.90\n",
      "[Val] Avg. Loss: 0.33, Avg. Metric: 0.84\n",
      "\n",
      "# Epoch 36 #\n",
      "\n",
      "[Train] Avg. Loss: 0.31, Avg. Metric: 0.90\n",
      "[Val] Avg. Loss: 0.30, Avg. Metric: 0.84\n",
      "\n",
      "# Epoch 37 #\n",
      "\n",
      "[Train] Avg. Loss: 0.27, Avg. Metric: 0.90\n",
      "[Val] Avg. Loss: 0.29, Avg. Metric: 0.84\n",
      "\n",
      "# Epoch 38 #\n",
      "\n",
      "[Train] Avg. Loss: 0.26, Avg. Metric: 0.90\n",
      "[Val] Avg. Loss: 0.28, Avg. Metric: 0.83\n",
      "\n",
      "# Epoch 39 #\n",
      "\n",
      "[Train] Avg. Loss: 0.23, Avg. Metric: 0.91\n",
      "[Val] Avg. Loss: 0.24, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 40 #\n",
      "\n",
      "[Train] Avg. Loss: 0.22, Avg. Metric: 0.91\n",
      "[Val] Avg. Loss: 0.25, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 41 #\n",
      "\n",
      "[Train] Avg. Loss: 0.20, Avg. Metric: 0.91\n",
      "[Val] Avg. Loss: 0.24, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 42 #\n",
      "\n",
      "[Train] Avg. Loss: 0.19, Avg. Metric: 0.91\n",
      "[Val] Avg. Loss: 0.21, Avg. Metric: 0.86\n",
      "\n",
      "# Epoch 43 #\n",
      "\n",
      "[Train] Avg. Loss: 0.19, Avg. Metric: 0.91\n",
      "[Val] Avg. Loss: 0.21, Avg. Metric: 0.86\n",
      "\n",
      "# Epoch 44 #\n",
      "\n",
      "[Train] Avg. Loss: 0.18, Avg. Metric: 0.91\n",
      "[Val] Avg. Loss: 0.21, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 45 #\n",
      "\n",
      "[Train] Avg. Loss: 0.17, Avg. Metric: 0.91\n",
      "[Val] Avg. Loss: 0.21, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 46 #\n",
      "\n",
      "[Train] Avg. Loss: 0.15, Avg. Metric: 0.92\n",
      "[Val] Avg. Loss: 0.18, Avg. Metric: 0.87\n",
      "\n",
      "# Epoch 47 #\n",
      "\n",
      "[Train] Avg. Loss: 0.15, Avg. Metric: 0.92\n",
      "[Val] Avg. Loss: 0.17, Avg. Metric: 0.87\n",
      "\n",
      "# Epoch 48 #\n",
      "\n",
      "[Train] Avg. Loss: 0.14, Avg. Metric: 0.92\n",
      "[Val] Avg. Loss: 0.18, Avg. Metric: 0.86\n",
      "\n",
      "# Epoch 49 #\n",
      "\n",
      "[Train] Avg. Loss: 0.14, Avg. Metric: 0.92\n",
      "[Val] Avg. Loss: 0.18, Avg. Metric: 0.86\n",
      "\n",
      "# Epoch 50 #\n",
      "\n",
      "[Train] Avg. Loss: 0.13, Avg. Metric: 0.92\n",
      "[Val] Avg. Loss: 0.20, Avg. Metric: 0.84\n",
      "\n",
      "# Epoch 51 #\n",
      "\n",
      "[Train] Avg. Loss: 0.13, Avg. Metric: 0.92\n",
      "[Val] Avg. Loss: 0.18, Avg. Metric: 0.86\n",
      "\n",
      "# Epoch 52 #\n",
      "\n",
      "[Train] Avg. Loss: 0.13, Avg. Metric: 0.92\n",
      "[Val] Avg. Loss: 0.18, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 53 #\n",
      "\n",
      "[Train] Avg. Loss: 0.12, Avg. Metric: 0.92\n",
      "[Val] Avg. Loss: 0.18, Avg. Metric: 0.86\n",
      "\n",
      "# Epoch 54 #\n",
      "\n",
      "[Train] Avg. Loss: 0.11, Avg. Metric: 0.92\n",
      "[Val] Avg. Loss: 0.17, Avg. Metric: 0.86\n",
      "\n",
      "# Epoch 55 #\n",
      "\n",
      "[Train] Avg. Loss: 0.11, Avg. Metric: 0.92\n",
      "[Val] Avg. Loss: 0.18, Avg. Metric: 0.84\n",
      "\n",
      "# Epoch 56 #\n",
      "\n",
      "[Train] Avg. Loss: 0.11, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.17, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 57 #\n",
      "\n",
      "[Train] Avg. Loss: 0.11, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.18, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 58 #\n",
      "\n",
      "[Train] Avg. Loss: 0.10, Avg. Metric: 0.92\n",
      "[Val] Avg. Loss: 0.17, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 59 #\n",
      "\n",
      "[Train] Avg. Loss: 0.11, Avg. Metric: 0.92\n",
      "[Val] Avg. Loss: 0.17, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 60 #\n",
      "\n",
      "[Train] Avg. Loss: 0.11, Avg. Metric: 0.92\n",
      "[Val] Avg. Loss: 0.17, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 61 #\n",
      "\n",
      "[Train] Avg. Loss: 0.09, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.15, Avg. Metric: 0.87\n",
      "\n",
      "# Epoch 62 #\n",
      "\n",
      "[Train] Avg. Loss: 0.10, Avg. Metric: 0.92\n",
      "[Val] Avg. Loss: 0.17, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 63 #\n",
      "\n",
      "[Train] Avg. Loss: 0.10, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.17, Avg. Metric: 0.84\n",
      "\n",
      "# Epoch 64 #\n",
      "\n",
      "[Train] Avg. Loss: 0.09, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.17, Avg. Metric: 0.84\n",
      "\n",
      "# Epoch 65 #\n",
      "\n",
      "[Train] Avg. Loss: 0.09, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.16, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 66 #\n",
      "\n",
      "[Train] Avg. Loss: 0.09, Avg. Metric: 0.92\n",
      "[Val] Avg. Loss: 0.15, Avg. Metric: 0.86\n",
      "\n",
      "# Epoch 67 #\n",
      "\n",
      "[Train] Avg. Loss: 0.09, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.16, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 68 #\n",
      "\n",
      "[Train] Avg. Loss: 0.09, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.16, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 69 #\n",
      "\n",
      "[Train] Avg. Loss: 0.09, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.16, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 70 #\n",
      "\n",
      "[Train] Avg. Loss: 0.09, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.16, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 71 #\n",
      "\n",
      "[Train] Avg. Loss: 0.09, Avg. Metric: 0.92\n",
      "[Val] Avg. Loss: 0.15, Avg. Metric: 0.86\n",
      "\n",
      "# Epoch 72 #\n",
      "\n",
      "[Train] Avg. Loss: 0.09, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.16, Avg. Metric: 0.84\n",
      "\n",
      "# Epoch 73 #\n",
      "\n",
      "[Train] Avg. Loss: 0.08, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.14, Avg. Metric: 0.87\n",
      "\n",
      "# Epoch 74 #\n",
      "\n",
      "[Train] Avg. Loss: 0.08, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.14, Avg. Metric: 0.87\n",
      "\n",
      "# Epoch 75 #\n",
      "\n",
      "[Train] Avg. Loss: 0.08, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.17, Avg. Metric: 0.84\n",
      "\n",
      "# Epoch 76 #\n",
      "\n",
      "[Train] Avg. Loss: 0.09, Avg. Metric: 0.92\n",
      "[Val] Avg. Loss: 0.16, Avg. Metric: 0.84\n",
      "\n",
      "# Epoch 77 #\n",
      "\n",
      "[Train] Avg. Loss: 0.08, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.16, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 78 #\n",
      "\n",
      "[Train] Avg. Loss: 0.08, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.15, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 79 #\n",
      "\n",
      "[Train] Avg. Loss: 0.08, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.14, Avg. Metric: 0.86\n",
      "\n",
      "# Epoch 80 #\n",
      "\n",
      "[Train] Avg. Loss: 0.08, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.17, Avg. Metric: 0.84\n",
      "\n",
      "# Epoch 81 #\n",
      "\n",
      "[Train] Avg. Loss: 0.08, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.16, Avg. Metric: 0.84\n",
      "\n",
      "# Epoch 82 #\n",
      "\n",
      "[Train] Avg. Loss: 0.08, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.14, Avg. Metric: 0.86\n",
      "\n",
      "# Epoch 83 #\n",
      "\n",
      "[Train] Avg. Loss: 0.08, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.16, Avg. Metric: 0.84\n",
      "\n",
      "# Epoch 84 #\n",
      "\n",
      "[Train] Avg. Loss: 0.08, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.15, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 85 #\n",
      "\n",
      "[Train] Avg. Loss: 0.08, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.16, Avg. Metric: 0.84\n",
      "\n",
      "# Epoch 86 #\n",
      "\n",
      "[Train] Avg. Loss: 0.07, Avg. Metric: 0.94\n",
      "[Val] Avg. Loss: 0.15, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 87 #\n",
      "\n",
      "[Train] Avg. Loss: 0.07, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.16, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 88 #\n",
      "\n",
      "[Train] Avg. Loss: 0.07, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.17, Avg. Metric: 0.83\n",
      "\n",
      "# Epoch 89 #\n",
      "\n",
      "[Train] Avg. Loss: 0.07, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.15, Avg. Metric: 0.86\n",
      "\n",
      "# Epoch 90 #\n",
      "\n",
      "[Train] Avg. Loss: 0.07, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.16, Avg. Metric: 0.84\n",
      "\n",
      "# Epoch 91 #\n",
      "\n",
      "[Train] Avg. Loss: 0.07, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.17, Avg. Metric: 0.83\n",
      "\n",
      "# Epoch 92 #\n",
      "\n",
      "[Train] Avg. Loss: 0.07, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.15, Avg. Metric: 0.86\n",
      "\n",
      "# Epoch 93 #\n",
      "\n",
      "[Train] Avg. Loss: 0.07, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.17, Avg. Metric: 0.83\n",
      "\n",
      "# Epoch 94 #\n",
      "\n",
      "[Train] Avg. Loss: 0.07, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.15, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 95 #\n",
      "\n",
      "[Train] Avg. Loss: 0.07, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.13, Avg. Metric: 0.87\n",
      "\n",
      "# Epoch 96 #\n",
      "\n",
      "[Train] Avg. Loss: 0.07, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.14, Avg. Metric: 0.86\n",
      "\n",
      "# Epoch 97 #\n",
      "\n",
      "[Train] Avg. Loss: 0.07, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.15, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 98 #\n",
      "\n",
      "[Train] Avg. Loss: 0.07, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.15, Avg. Metric: 0.85\n",
      "\n",
      "# Epoch 99 #\n",
      "\n",
      "[Train] Avg. Loss: 0.07, Avg. Metric: 0.94\n",
      "[Val] Avg. Loss: 0.14, Avg. Metric: 0.86\n",
      "\n",
      "# Epoch 100 #\n",
      "\n",
      "[Train] Avg. Loss: 0.07, Avg. Metric: 0.93\n",
      "[Val] Avg. Loss: 0.15, Avg. Metric: 0.85\n",
      "\n",
      "Time elapsed: 55608.54 seconds\n"
     ]
    }
   ],
   "source": [
    "# with proposed augmentations\n",
    "# pretrained 2019\n",
    "# lr=0.0001, epochs=50, num_batches_per_epoch=100, num_validation_batches_per_epoch=100\n",
    "# ~4.5 hrs\n",
    "# batch_size = 24, patch_size = [24, 128, 128]\n",
    "model_trainer.run()\n",
    "model_trainer.save_model('models/pr_augm_lr_0001_epochs_100_bs_24.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.load_model('models/pr_augm_lr_0001_epochs_100_bs_24.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import SimpleITK as sitk\n",
    "except ImportError:\n",
    "    print(\"You need to have SimpleITK installed to run this example!\")\n",
    "    raise ImportError(\"SimpleITK not found\")\n",
    "\n",
    "def save_segmentation_as_nifti(segmentation, metadata, output_file):\n",
    "    original_shape = metadata['original_shape']\n",
    "    seg_original_shape = np.zeros(original_shape, dtype=np.uint8)\n",
    "    nonzero = metadata['nonzero_region']\n",
    "    seg_original_shape[nonzero[0, 0] : nonzero[0, 1] + 1,\n",
    "               nonzero[1, 0]: nonzero[1, 1] + 1,\n",
    "               nonzero[2, 0]: nonzero[2, 1] + 1] = segmentation\n",
    "    sitk_image = sitk.GetImageFromArray(seg_original_shape)\n",
    "    sitk_image.SetDirection(metadata['direction'])\n",
    "    sitk_image.SetOrigin(metadata['origin'])\n",
    "    # remember to revert spacing back to sitk order again\n",
    "    sitk_image.SetSpacing(tuple(metadata['spacing'][[2, 1, 0]]))\n",
    "    print(output_file)\n",
    "    sitk.WriteImage(sitk_image, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_dice(outputs, targets):\n",
    "\n",
    "    # try without sigmoid\n",
    "    # outputs = F.sigmoid(outputs)\n",
    "    outputs = np.float32(outputs>0)\n",
    "    smooth = 1e-15\n",
    "\n",
    "    targets = np.float32((targets == 1) | (targets == 3))\n",
    "    union_fg = np.sum(outputs+targets) + smooth\n",
    "    intersection_fg = np.sum(outputs*targets) + smooth\n",
    "\n",
    "    dice = 2 * intersection_fg / union_fg\n",
    "\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "\n",
    "def predict_patient_in_patches(patient_data, model):\n",
    "    # we pad the patient data in order to fit the patches in it\n",
    "    patient_data_pd = pad_nd_image(patient_data, [144, 192, 192]) # 24*6, 128+2*32, 128+2*32\n",
    "    # patches.shape = (1, 1, 6, 3, 3, 1, 3, 24, 128, 128)\n",
    "    steps = (1,1,24,32,32)\n",
    "    window_shape = (1, 3, 24, 128, 128)\n",
    "    patches = skimage.util.view_as_windows(patient_data_pd[:, :3, :, :, :], window_shape=window_shape, step=steps)\n",
    "    \n",
    "    # (1, 4, 138, 169, 141)\n",
    "    target_shape = list(patient_data_pd.shape)\n",
    "    target_shape[1] = 1 # only one output channel\n",
    "    prediction = torch.zeros(*target_shape).cuda()\n",
    "    \n",
    "    for i in range(patches.shape[2]):\n",
    "        for j in range(patches.shape[3]):\n",
    "            for k in range(patches.shape[4]):\n",
    "                data = torch.from_numpy(patches[0, 0, i, j, k])\n",
    "                data = data.cuda()\n",
    "                output = model.forward(data)\n",
    "\n",
    "                prediction[:, :,\n",
    "                           i*steps[2]:i*steps[2]+window_shape[2],\n",
    "                           j*steps[3]:j*steps[3]+window_shape[3],\n",
    "                           k*steps[4]:k*steps[4]+window_shape[4]] += output\n",
    "                    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 138, 169, 141)\n",
      "0 0.8375910612325261\n",
      "segmentation_output/Brats19TrainingData/BraTS19_2013_19_1.nii.gz\n",
      "(1, 4, 132, 175, 146)\n",
      "1 0.6555020584746354\n",
      "segmentation_output/Brats19TrainingData/BraTS19_2013_1_1.nii.gz\n",
      "(1, 4, 130, 165, 141)\n",
      "2 0.928977473758698\n",
      "segmentation_output/Brats19TrainingData/BraTS19_2013_24_1.nii.gz\n",
      "(1, 4, 128, 180, 141)\n",
      "3 0.9455917394757745\n",
      "segmentation_output/Brats19TrainingData/BraTS19_2013_26_1.nii.gz\n",
      "(1, 4, 142, 166, 149)\n",
      "4 0.9275800998228949\n",
      "segmentation_output/Brats19TrainingData/BraTS19_2013_27_1.nii.gz\n",
      "(1, 4, 133, 161, 149)\n",
      "5 0.16364931343481356\n",
      "segmentation_output/Brats19TrainingData/BraTS19_2013_28_1.nii.gz\n",
      "(1, 4, 129, 179, 142)\n",
      "6 0.9222455013608506\n",
      "segmentation_output/Brats19TrainingData/BraTS19_2013_2_1.nii.gz\n",
      "(1, 4, 132, 159, 137)\n",
      "7 0.9517716747442111\n",
      "segmentation_output/Brats19TrainingData/BraTS19_2013_7_1.nii.gz\n",
      "(1, 4, 140, 187, 134)\n",
      "8 0.9572199301808949\n",
      "segmentation_output/Brats19TrainingData/BraTS19_CBICA_AAG_1.nii.gz\n",
      "(1, 4, 140, 182, 135)\n",
      "9 0.9285700334003946\n",
      "segmentation_output/Brats19TrainingData/BraTS19_CBICA_AAP_1.nii.gz\n",
      "(1, 4, 141, 177, 133)\n",
      "10 0.931846798379158\n",
      "segmentation_output/Brats19TrainingData/BraTS19_CBICA_ABE_1.nii.gz\n",
      "(1, 4, 142, 160, 152)\n",
      "11 0.9061350880588349\n",
      "segmentation_output/Brats19TrainingData/BraTS19_CBICA_ALN_1.nii.gz\n",
      "(1, 4, 143, 178, 138)\n",
      "12 0.9190934492393666\n",
      "segmentation_output/Brats19TrainingData/BraTS19_CBICA_ALU_1.nii.gz\n",
      "(1, 4, 140, 171, 129)\n",
      "13 0.9667938391974\n",
      "segmentation_output/Brats19TrainingData/BraTS19_CBICA_AOC_1.nii.gz\n",
      "(1, 4, 136, 157, 133)\n",
      "14 0.8588391670358884\n",
      "segmentation_output/Brats19TrainingData/BraTS19_CBICA_AOH_1.nii.gz\n",
      "(1, 4, 147, 168, 127)\n",
      "15 0.9411203529797574\n",
      "segmentation_output/Brats19TrainingData/BraTS19_CBICA_AOP_1.nii.gz\n",
      "(1, 4, 134, 169, 163)\n",
      "16 0.9608863464056793\n",
      "segmentation_output/Brats19TrainingData/BraTS19_CBICA_AOS_1.nii.gz\n",
      "(1, 4, 130, 167, 148)\n",
      "17 0.8450833762167015\n",
      "segmentation_output/Brats19TrainingData/BraTS19_CBICA_AQQ_1.nii.gz\n",
      "(1, 4, 140, 187, 137)\n",
      "18 0.9506997184060073\n",
      "segmentation_output/Brats19TrainingData/BraTS19_CBICA_AQY_1.nii.gz\n",
      "(1, 4, 142, 165, 142)\n",
      "19 0.957034394778236\n",
      "segmentation_output/Brats19TrainingData/BraTS19_CBICA_ARF_1.nii.gz\n",
      "(1, 4, 137, 167, 124)\n",
      "20 0.9080495481500493\n",
      "segmentation_output/Brats19TrainingData/BraTS19_CBICA_AUR_1.nii.gz\n",
      "(1, 4, 141, 169, 135)\n",
      "21 0.9327148011577654\n",
      "segmentation_output/Brats19TrainingData/BraTS19_CBICA_AUX_1.nii.gz\n",
      "(1, 4, 142, 185, 132)\n",
      "22 0.887802640443801\n",
      "segmentation_output/Brats19TrainingData/BraTS19_CBICA_AWI_1.nii.gz\n",
      "(1, 4, 140, 169, 142)\n",
      "23 0.9338314136487842\n",
      "segmentation_output/Brats19TrainingData/BraTS19_CBICA_AWV_1.nii.gz\n",
      "(1, 4, 139, 175, 132)\n",
      "24 0.28093903811863696\n",
      "segmentation_output/Brats19TrainingData/BraTS19_CBICA_AXJ_1.nii.gz\n",
      "(1, 4, 140, 170, 136)\n",
      "25 0.907718405428329\n",
      "segmentation_output/Brats19TrainingData/BraTS19_CBICA_AZD_1.nii.gz\n",
      "(1, 4, 142, 164, 139)\n",
      "26 0.9642279345676793\n",
      "segmentation_output/Brats19TrainingData/BraTS19_CBICA_BAX_1.nii.gz\n",
      "(1, 4, 138, 155, 139)\n",
      "27 0.8078084121553633\n",
      "segmentation_output/Brats19TrainingData/BraTS19_CBICA_BCF_1.nii.gz\n",
      "(1, 4, 137, 171, 138)\n",
      "28 0.9482868424404535\n",
      "segmentation_output/Brats19TrainingData/BraTS19_CBICA_BGT_1.nii.gz\n",
      "(1, 4, 142, 163, 142)\n",
      "29 0.6487539285556195\n",
      "segmentation_output/Brats19TrainingData/BraTS19_CBICA_BNR_1.nii.gz\n",
      "(1, 4, 136, 165, 140)\n",
      "30 0.9269700735217976\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA01_150_1.nii.gz\n",
      "(1, 4, 139, 152, 138)\n",
      "31 0.8592897567939631\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA01_180_1.nii.gz\n",
      "(1, 4, 133, 171, 144)\n",
      "32 0.9389680150923833\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA01_201_1.nii.gz\n",
      "(1, 4, 140, 167, 139)\n",
      "33 0.9579074153314633\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA01_401_1.nii.gz\n",
      "(1, 4, 132, 153, 148)\n",
      "34 0.9601085946289684\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA01_429_1.nii.gz\n",
      "(1, 4, 144, 163, 133)\n",
      "35 0.8727532909773889\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA01_460_1.nii.gz\n",
      "(1, 4, 134, 161, 135)\n",
      "36 0.9284443900740588\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA02_118_1.nii.gz\n",
      "(1, 4, 139, 170, 136)\n",
      "37 0.9081565787204691\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA02_179_1.nii.gz\n",
      "(1, 4, 138, 173, 143)\n",
      "38 0.8920401337792642\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA02_309_1.nii.gz\n",
      "(1, 4, 131, 157, 142)\n",
      "39 0.9624383325647562\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA02_377_1.nii.gz\n",
      "(1, 4, 138, 170, 144)\n",
      "40 0.9176655789318334\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA02_394_1.nii.gz\n",
      "(1, 4, 139, 176, 138)\n",
      "41 0.9596735219889384\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA02_455_1.nii.gz\n",
      "(1, 4, 136, 177, 133)\n",
      "42 0.9522505785339461\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA02_607_1.nii.gz\n",
      "(1, 4, 139, 165, 147)\n",
      "43 0.8653524552779608\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA03_133_1.nii.gz\n",
      "(1, 4, 137, 171, 139)\n",
      "44 0.8208463088477743\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA04_328_1.nii.gz\n",
      "(1, 4, 136, 167, 137)\n",
      "45 0.9635740183816296\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA04_479_1.nii.gz\n",
      "(1, 4, 130, 169, 152)\n",
      "46 0.953109874933853\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA05_478_1.nii.gz\n",
      "(1, 4, 143, 175, 134)\n",
      "47 0.7525666688190095\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA06_165_1.nii.gz\n",
      "(1, 4, 132, 168, 142)\n",
      "48 0.9137232502224997\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA06_247_1.nii.gz\n",
      "(1, 4, 135, 164, 144)\n",
      "49 0.9486317375186601\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA08_167_1.nii.gz\n",
      "(1, 4, 145, 181, 138)\n",
      "50 0.924987453168221\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA09_402_1.nii.gz\n",
      "(1, 4, 140, 166, 134)\n",
      "51 0.2702628445828373\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA09_462_1.nii.gz\n",
      "(1, 4, 137, 163, 145)\n",
      "52 0.2530105273787584\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA10_103_1.nii.gz\n",
      "(1, 4, 136, 163, 135)\n",
      "53 0.6330400568337068\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA10_130_1.nii.gz\n",
      "(1, 4, 138, 161, 133)\n",
      "54 0.7630855594270228\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA10_175_1.nii.gz\n",
      "(1, 4, 134, 170, 133)\n",
      "55 0.8861950941243583\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA10_202_1.nii.gz\n",
      "(1, 4, 130, 165, 140)\n",
      "56 0.6973956163185492\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA10_261_1.nii.gz\n",
      "(1, 4, 141, 170, 137)\n",
      "57 0.9304662426328996\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA10_346_1.nii.gz\n",
      "(1, 4, 143, 173, 131)\n",
      "58 0.945471138489619\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA10_632_1.nii.gz\n",
      "(1, 4, 144, 168, 139)\n",
      "59 0.8985410908582024\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA12_249_1.nii.gz\n",
      "(1, 4, 131, 159, 138)\n",
      "60 0.9253271653782945\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA12_298_1.nii.gz\n",
      "(1, 4, 136, 153, 135)\n",
      "61 0.6498136619202516\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA13_615_1.nii.gz\n",
      "(1, 4, 140, 178, 134)\n",
      "62 0.5888739646295053\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA13_624_1.nii.gz\n",
      "(1, 4, 138, 176, 144)\n",
      "63 0.7179415037951258\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA13_633_1.nii.gz\n",
      "(1, 4, 139, 165, 138)\n",
      "64 0.17614002763703362\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA13_650_1.nii.gz\n",
      "(1, 4, 139, 189, 146)\n",
      "65 0.9162237583293855\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TCIA13_654_1.nii.gz\n",
      "(1, 4, 141, 168, 126)\n",
      "66 0.9291738802326097\n",
      "segmentation_output/Brats19TrainingData/BraTS19_TMC_27374_1.nii.gz\n",
      "Mean: 0.836369918536212\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Axis must be specified when shapes of a and weights differ.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-638edc42834a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m#    break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mean:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Weighted Average:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproportions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned)\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 raise TypeError(\n\u001b[0;32m-> 1142\u001b[0;31m                     \u001b[0;34m\"Axis must be specified when shapes of a and weights \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m                     \"differ.\")\n\u001b[1;32m   1144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Axis must be specified when shapes of a and weights differ."
     ]
    }
   ],
   "source": [
    "from batchgenerators.augmentations.utils import pad_nd_image\n",
    "from batchgenerators.augmentations.utils import center_crop_3D_image\n",
    "\n",
    "target_patients = patients_val\n",
    "\n",
    "dices = []\n",
    "\n",
    "for idx, (patient_data, meta_data) in enumerate(iterate_through_patients(target_patients, in_channels + ['seg'])): #  + ['seg']\n",
    "    print(patient_data.shape)\n",
    "    \n",
    "    model_trainer.model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = predict_patient_in_patches(patient_data, model_trainer.model)\n",
    "        \n",
    "    np_prediction = prediction.cpu().detach().numpy()\n",
    "    np_prediction[np_prediction > 0] = 1 # tumor core\n",
    "    np_prediction[np_prediction < 0] = 0\n",
    "    \n",
    "    np_cut = center_crop_3D_image(np_prediction[0,0], patient_data.shape[2:])\n",
    "    \n",
    "    dice = np_dice(np_cut, patient_data[0,3,:,:,:])\n",
    "    print(idx, dice)\n",
    "    dices.append(dice)\n",
    "    \n",
    "    output_path = '/'.join(target_patients[idx].split('/')[-2:])\n",
    "    save_segmentation_as_nifti(np_cut, meta_data, os.path.join('segmentation_output', output_path + '.nii.gz'))\n",
    "    \n",
    "print('Mean:', np.mean(np.array(dices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
